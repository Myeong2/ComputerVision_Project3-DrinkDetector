{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcF4zygesuVW/sbH+NBZw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Myeong2/ComputerVision_Project3-DrinkDetector/blob/master/%EC%95%A1%ED%84%B0_%ED%81%AC%EB%A6%AC%ED%8B%B1_%EC%82%AC%EC%9A%A9_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-81iBdzlSRl",
        "outputId": "d8065a79-635b-45f1-b073-ab0a26577272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "<ipython-input-1-d56456db05b1>:80: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  s_batch = torch.tensor(S, dtype=torch.float)\n",
            "<ipython-input-1-d56456db05b1>:98: UserWarning: Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = -torch.log(pi_a) * TD_error.detach() + F.smooth_l1_loss(self.v(s), TD_target.detach())\n",
            "<ipython-input-1-d56456db05b1>:98: UserWarning: Using a target size (torch.Size([4, 4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = -torch.log(pi_a) * TD_error.detach() + F.smooth_l1_loss(self.v(s), TD_target.detach())\n",
            "<ipython-input-1-d56456db05b1>:98: UserWarning: Using a target size (torch.Size([3, 3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = -torch.log(pi_a) * TD_error.detach() + F.smooth_l1_loss(self.v(s), TD_target.detach())\n",
            "<ipython-input-1-d56456db05b1>:98: UserWarning: Using a target size (torch.Size([2, 2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = -torch.log(pi_a) * TD_error.detach() + F.smooth_l1_loss(self.v(s), TD_target.detach())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에피소드: 20, 평균 점수: 20.75\n",
            "에피소드: 40, 평균 점수: 15.8\n",
            "에피소드: 60, 평균 점수: 16.9\n",
            "에피소드: 80, 평균 점수: 16.8\n",
            "에피소드: 100, 평균 점수: 19.75\n",
            "에피소드: 120, 평균 점수: 17.25\n",
            "에피소드: 140, 평균 점수: 17.2\n",
            "에피소드: 160, 평균 점수: 16.05\n",
            "에피소드: 180, 평균 점수: 17.7\n",
            "에피소드: 200, 평균 점수: 16.1\n",
            "에피소드: 220, 평균 점수: 16.3\n",
            "에피소드: 240, 평균 점수: 19.35\n",
            "에피소드: 260, 평균 점수: 18.8\n",
            "에피소드: 280, 평균 점수: 18.7\n",
            "에피소드: 300, 평균 점수: 18.3\n",
            "에피소드: 320, 평균 점수: 25.4\n",
            "에피소드: 340, 평균 점수: 20.65\n",
            "에피소드: 360, 평균 점수: 22.85\n",
            "에피소드: 380, 평균 점수: 20.4\n",
            "에피소드: 400, 평균 점수: 25.45\n",
            "에피소드: 420, 평균 점수: 18.9\n",
            "에피소드: 440, 평균 점수: 21.8\n",
            "에피소드: 460, 평균 점수: 21.3\n",
            "에피소드: 480, 평균 점수: 25.85\n",
            "에피소드: 500, 평균 점수: 29.4\n",
            "에피소드: 520, 평균 점수: 32.55\n",
            "에피소드: 540, 평균 점수: 31.5\n",
            "에피소드: 560, 평균 점수: 27.2\n",
            "에피소드: 580, 평균 점수: 31.95\n",
            "에피소드: 600, 평균 점수: 32.7\n",
            "에피소드: 620, 평균 점수: 35.95\n",
            "에피소드: 640, 평균 점수: 33.2\n",
            "에피소드: 660, 평균 점수: 41.05\n",
            "에피소드: 680, 평균 점수: 32.65\n",
            "에피소드: 700, 평균 점수: 40.95\n",
            "에피소드: 720, 평균 점수: 41.25\n",
            "에피소드: 740, 평균 점수: 43.95\n",
            "에피소드: 760, 평균 점수: 28.95\n",
            "에피소드: 780, 평균 점수: 39.65\n",
            "에피소드: 800, 평균 점수: 50.1\n",
            "에피소드: 820, 평균 점수: 46.1\n",
            "에피소드: 840, 평균 점수: 39.65\n",
            "에피소드: 860, 평균 점수: 39.8\n",
            "에피소드: 880, 평균 점수: 42.55\n",
            "에피소드: 900, 평균 점수: 39.8\n",
            "에피소드: 920, 평균 점수: 39.45\n",
            "에피소드: 940, 평균 점수: 40.85\n",
            "에피소드: 960, 평균 점수: 42.0\n",
            "에피소드: 980, 평균 점수: 48.25\n",
            "에피소드: 1000, 평균 점수: 44.2\n",
            "에피소드: 1020, 평균 점수: 59.25\n",
            "에피소드: 1040, 평균 점수: 55.7\n",
            "에피소드: 1060, 평균 점수: 60.65\n",
            "에피소드: 1080, 평균 점수: 56.25\n",
            "에피소드: 1100, 평균 점수: 69.4\n",
            "에피소드: 1120, 평균 점수: 68.8\n",
            "에피소드: 1140, 평균 점수: 69.8\n",
            "에피소드: 1160, 평균 점수: 69.15\n",
            "에피소드: 1180, 평균 점수: 62.85\n",
            "에피소드: 1200, 평균 점수: 67.85\n",
            "에피소드: 1220, 평균 점수: 87.45\n",
            "에피소드: 1240, 평균 점수: 58.35\n",
            "에피소드: 1260, 평균 점수: 108.65\n",
            "에피소드: 1280, 평균 점수: 93.2\n",
            "에피소드: 1300, 평균 점수: 81.45\n",
            "에피소드: 1320, 평균 점수: 87.25\n",
            "에피소드: 1340, 평균 점수: 105.25\n",
            "에피소드: 1360, 평균 점수: 115.95\n",
            "에피소드: 1380, 평균 점수: 120.1\n",
            "에피소드: 1400, 평균 점수: 131.3\n",
            "에피소드: 1420, 평균 점수: 142.3\n",
            "에피소드: 1440, 평균 점수: 149.3\n",
            "에피소드: 1460, 평균 점수: 157.05\n",
            "에피소드: 1480, 평균 점수: 142.3\n",
            "에피소드: 1500, 평균 점수: 174.5\n",
            "에피소드: 1520, 평균 점수: 179.7\n",
            "에피소드: 1540, 평균 점수: 168.75\n",
            "에피소드: 1560, 평균 점수: 124.3\n",
            "에피소드: 1580, 평균 점수: 183.7\n",
            "에피소드: 1600, 평균 점수: 186.5\n",
            "에피소드: 1620, 평균 점수: 173.45\n",
            "에피소드: 1640, 평균 점수: 164.0\n",
            "에피소드: 1660, 평균 점수: 129.8\n",
            "에피소드: 1680, 평균 점수: 136.25\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "lr = 0.0002\n",
        "gamma = 0.98\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    model = ActorCritic(lr) # 학습률(lr)을 인자로 넘겨줍니다\n",
        "    n_rollout = 5 # 5번의 step마다 update 진행\n",
        "    print_int = 20\n",
        "    score = 0\n",
        "\n",
        "    for episode in range(2000):\n",
        "        done = False\n",
        "        state = env.reset()\n",
        "        while not done:\n",
        "            for t in range(n_rollout):\n",
        "                prob = model.pi(torch.from_numpy(state).float()) # 확률로 변환\n",
        "                actions = Categorical(prob).sample() # 확률에 따라 행동을 샘플링\n",
        "                state_, returns, done, info = env.step(actions.item())\n",
        "                model.put_data((state, actions, returns, state_, done))\n",
        "                state = state_ # 다음 상태로 넘어감\n",
        "                score += returns # 리턴을 누적해서 더함\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            model.train() # 모델 학습을 위해 train 함수를 호출\n",
        "\n",
        "        if episode % print_int == 0 and episode != 0:\n",
        "            print('에피소드: {}, 평균 점수: {}'.format(episode, score / print_int))\n",
        "            score = 0\n",
        "\n",
        "    env.close()\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, lr):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.data = []\n",
        "        self.fc_common = nn.Linear(4, 128)\n",
        "        self.fc_pi = nn.Linear(128, 2)\n",
        "        self.fc_v = nn.Linear(128, 1)\n",
        "        self.opt = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "    ## REINFORCE와는 다르게, 훈련시켜야하는 network가 2개(pi & v)다\n",
        "    def pi(self, x, dim=0): # 수정: \"sef\" 대신 \"self\" 사용, dim의 기본값을 0으로 설정하여 배치 차원에 대해 softmax 적용\n",
        "        x = F.relu(self.fc_common(x))\n",
        "        x = self.fc_pi(x)\n",
        "        pi = F.softmax(x, dim=dim) # 각 행동에 대한 확률 반환\n",
        "        return pi\n",
        "\n",
        "    def v(self, x):\n",
        "        x = F.relu(self.fc_common(x))\n",
        "        v = self.fc_v(x)\n",
        "        return v\n",
        "\n",
        "    def put_data(self, item):\n",
        "        self.data.append(item)\n",
        "\n",
        "    def batch(self):\n",
        "        S, A, R, S_, Done = [], [], [], [], []\n",
        "\n",
        "        for item in self.data:\n",
        "            s, a, r, s_, done = item\n",
        "            S.append(s)\n",
        "            A.append([a])\n",
        "            R.append([r / 100.0])\n",
        "            S_.append(s_)\n",
        "            if done:\n",
        "                d = 0\n",
        "            else:\n",
        "                d = 1\n",
        "            Done.append([d])\n",
        "\n",
        "        s_batch = torch.tensor(S, dtype=torch.float)\n",
        "        a_batch = torch.tensor(A, dtype=torch.float) # 수정: 쉼표(,) 제거\n",
        "        r_batch = torch.tensor(R, dtype=torch.float) # 수정: 쉼표(,) 제거\n",
        "        s2_batch = torch.tensor(S_, dtype=torch.float) # 수정: 쉼표(,) 제거\n",
        "        d_batch = torch.tensor(Done, dtype=torch.float) # 수정: 쉼표(,) 제거\n",
        "        self.data = []\n",
        "\n",
        "        return s_batch, a_batch, r_batch, s2_batch, d_batch\n",
        "\n",
        "    def train(self):\n",
        "        s, a, r, s_, done = self.batch()\n",
        "        with torch.no_grad():\n",
        "            v_s_ = self.v(s_).squeeze()  # 불필요한 차원을 제거하여 1차원 텐서로 변환\n",
        "            TD_target = r + gamma * v_s_ * done  # TD 타겟 계산\n",
        "            TD_error = TD_target - self.v(s).squeeze()  # 불필요한 차원을 제거하여 1차원 텐서로 변환\n",
        "\n",
        "        pi = self.pi(s, dim=1)\n",
        "        pi_a = pi.gather(1, a.long())\n",
        "        loss = -torch.log(pi_a) * TD_error.detach() + F.smooth_l1_loss(self.v(s), TD_target.detach())\n",
        "\n",
        "        self.opt.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.opt.step()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}